#!/usr/bin/env python3
"""Test runner script for the Open Host Factory Plugin."""

import argparse
import logging
import subprocess
import sys

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)


def run_command(cmd: list[str], description: str) -> bool:
    """Run a command and return success status."""
    logger.info(f"Running: {description}")
    logger.debug(f"Command: {' '.join(cmd)}")

    try:
        subprocess.run(cmd, check=True, capture_output=False)
        logger.info(f"PASS {description}")
        return True
    except subprocess.CalledProcessError as e:
        logger.error(f"FAIL {description} (exit code: {e.returncode})")
        return False
    except FileNotFoundError:
        logger.error(f"FAIL {description} (command not found)")
        return False


def main():
    """Main test runner function."""
    parser = argparse.ArgumentParser(description="Run tests for Open Host Factory Plugin")
    parser.add_argument("--unit", action="store_true", help="Run unit tests only")
    parser.add_argument("--integration", action="store_true", help="Run integration tests only")
    parser.add_argument("--e2e", action="store_true", help="Run end-to-end tests only")
    parser.add_argument("--onaws", action="store_true", help="Run AWS integration tests only")
    parser.add_argument("--coverage", action="store_true", help="Run tests with coverage")
    parser.add_argument(
        "--html-coverage", action="store_true", help="Generate HTML coverage report"
    )
    parser.add_argument("--parallel", action="store_true", help="Run tests in parallel")
    parser.add_argument("--verbose", "-v", action="store_true", help="Verbose output")
    parser.add_argument("--fast", action="store_true", help="Skip slow tests")
    parser.add_argument("--markers", type=str, help="Run tests with specific markers")
    parser.add_argument("--path", type=str, help="Run tests in specific path")
    parser.add_argument("--keyword", "-k", type=str, help="Run tests matching keyword")
    parser.add_argument(
        "--ci",
        action="store_true",
        help="Enable CI-specific outputs (XML reports, coverage)",
    )
    parser.add_argument("--junit-xml", type=str, help="Generate JUnit XML report")
    parser.add_argument("--cov-xml", type=str, help="Generate coverage XML report")
    parser.add_argument("--all", action="store_true", help="Run all test types")
    parser.add_argument("--maxfail", type=int, default=5, help="Stop after N failures")
    parser.add_argument("--timeout", type=int, default=300, help="Test timeout in seconds")
    parser.add_argument(
        "extra_args", nargs="*", help="Additional paths, patterns, or pytest options"
    )

    args = parser.parse_args()

    # Parse mixed arguments (paths, patterns, pytest options)
    extra_paths = []
    extra_pytest_args = []

    for arg in args.extra_args:
        if arg.startswith("-"):
            # Pytest option (e.g., -v, -s, --tb=short, -x)
            extra_pytest_args.append(arg)
        elif "/" in arg or arg.endswith(".py") or arg in ["tests", "unit", "integration", "e2e"]:
            # Path or directory
            extra_paths.append(arg)
        else:
            # Treat as keyword pattern
            extra_pytest_args.extend(["-k", arg])

    # Base pytest command
    pytest_cmd = ["python", "-m", "pytest"]

    # Add verbosity
    if args.verbose:
        pytest_cmd.append("-v")
    else:
        pytest_cmd.append("-q")

    # Add parallel execution (only if pytest-xdist is available)
    if args.parallel:
        try:
            import xdist  # type: ignore[import-untyped] # noqa: F401 - Used conditionally

            pytest_cmd.extend(["-n", "auto"])
        except ImportError:
            logger.warning("pytest-xdist not installed, skipping parallel execution")

    # Add timeout (only if pytest-timeout is available)
    try:
        import pytest_timeout  # noqa: F401 - Used conditionally

        pytest_cmd.extend(["--timeout", str(args.timeout)])
    except ImportError:
        logger.warning("pytest-timeout not installed, skipping timeout option")

    # Add maxfail
    pytest_cmd.extend(["--maxfail", str(args.maxfail)])

    # Disable coverage for onaws tests to avoid import issues
    if not args.onaws and (args.coverage or args.html_coverage or args.ci):
        pytest_cmd.extend(
            [
                "--cov=src",
                "--cov-report=term-missing",
                "--cov-branch",
                "--no-cov-on-fail",
            ]
        )

        if args.html_coverage:
            pytest_cmd.extend(["--cov-report=html:htmlcov"])

        if args.cov_xml:
            pytest_cmd.extend([f"--cov-report=xml:{args.cov_xml}"])
        elif args.ci:
            pytest_cmd.extend(["--cov-report=xml:coverage.xml"])
    elif args.onaws:
        # Explicitly disable coverage for onaws tests
        pytest_cmd.append("--no-cov")

    # Add JUnit XML output for CI
    if args.junit_xml:
        pytest_cmd.extend([f"--junitxml={args.junit_xml}"])
    elif args.ci:
        pytest_cmd.extend(["--junitxml=junit.xml"])

    # Use UV directly instead of the complex run_tool.sh script
    final_cmd = ["uv", "run"] + pytest_cmd
    test_paths = []
    markers = []

    if args.all:
        test_paths = ["tests/"]
    elif args.unit:
        test_paths.append("tests/unit")
        markers.append("unit")

    if args.integration:
        test_paths.append("tests/integration")
        markers.append("integration")

    if args.e2e:
        test_paths.append("tests/e2e")
        markers.append("e2e")

    if args.onaws:
        test_paths.append("tests/onaws")
        markers.append("aws")

    if args.fast:
        markers.append("not slow")

    if args.markers:
        markers.append(args.markers)

    # Add extra paths from command line
    if extra_paths:
        test_paths.extend(extra_paths)

    # If no specific test type selected and no extra paths, run default
    if not test_paths:
        test_paths = ["tests/"]

    # Add test paths
    pytest_cmd.extend(test_paths)

    # Add markers
    if markers:
        pytest_cmd.extend(["-m", " and ".join(markers)])

    # Add specific path if provided
    if args.path:
        pytest_cmd = ["python", "-m", "pytest", args.path]
        if args.verbose:
            pytest_cmd.append("-v")
        # Re-add markers for specific path
        if markers:
            pytest_cmd.extend(["-m", " and ".join(markers)])

    # Add keyword filter
    if args.keyword:
        pytest_cmd.extend(["-k", args.keyword])

    # Enable manual AWS flows when requested
    if args.onaws and "--run-manual-aws" not in pytest_cmd:
        pytest_cmd.append("--run-manual-aws")

    # Add extra pytest arguments from command line
    if extra_pytest_args:
        pytest_cmd.extend(extra_pytest_args)


    # Run the tests
    success = run_command(final_cmd, "Running Tests")

    if success:
        logger.info("All tests passed!")
        if args.html_coverage:
            logger.info("Coverage report generated in htmlcov/index.html")
    else:
        logger.error("Some tests failed!")
        sys.exit(1)


if __name__ == "__main__":
    main()
